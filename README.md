# Tokenizer_Ablation
This repo covers a series of Experiments on **Tokenizers**. To concentrate only on Tokenizers, all other things are fixed equally.

</br>

## Tokenization Methods

**Word Piece**
>

</br>

**Byte-Pair Encoding**
>

</br>

**Unigram**
>

</br>
</br>

## Experiments desc

| **`Varialbes`** | **`Elements`** |
| --- | --- |
|&nbsp; **`Tokenization Methods`** &nbsp;|&nbsp; **`Word Piece`**, **`Byte-Pair Encoding`**, **`Unigram`** &nbsp;|
|&nbsp; **`Pre-Tokenization`** &nbsp;|&nbsp; **`None`**, **`Moses`**, **`Mecab`** &nbsp;|
|&nbsp; **`Language`** &nbsp;|&nbsp; **`English`**, **`Korean`** &nbsp;|
|&nbsp; **`Engine`** &nbsp;|&nbsp; **`Sentencepiece`**, **`Hugging Face`** &nbsp;|


</br>
</br>

## Results

</br>
</br>

## References
